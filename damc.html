<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Data Analysis and Matrix Computations (Spring 2022)</title>
<!-- MathJax -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Kui Du</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href=" "></a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="nla.html">NLA</a></div>
<div class="menu-item"><a href="damc.html" class="current">DAMC</a></div>
<div class="menu-item"><a href="lip.html">LIP</a></div>
<div class="menu-item"><a href=" "></a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="talk.html">Talks</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Data Analysis and Matrix Computations (Spring 2022)</h1>
</div>
<ul>
<li><p>Prerequisites: &nbsp Calculus, Linear Algebra, Probability, Matlab Programming</p>
</li>
<li><p>Classes: &nbsp Tuesday 14:30-16:10, Haiyun 302; Thursday 14:30-16:10, Haiyun 302</p>
</li>
<li><p>Grading Policy: &nbsp Classroom performance & Assignments & Projects 60% + Final exam 40%</p>
</li>
<li><p>Highlights: &nbsp <b>教研结合型课程，侧重数据分析中的概率、矩阵计算、优化算法</b></p>
</li>
</ul>
<h2>Instructor</h2>
<ul>
<li><p><a href="http://kuidu.github.io" target=&ldquo;blank&rdquo;>Kui Du</a>, School of Mathematical Sciences, Xiamen University. Email: kuidu@xmu.edu.cn Tel: 0592-2580672<br />


</p>
</li>
</ul>
<h2>References</h2>
<ul>
<li><p>Mathematics of Data Science: A Computational Approach to Clustering and Classification, Daniela Calvetti and Erkki Somersalo, SIAM, 2021 </p>
</li>
<li><p><a href="https://doi.org/10.1007/978-0-387-84858-7" target=&ldquo;blank&rdquo;>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>, Trevor Hastie, Robert Tibshirani, and Jerome Friedman, Second Edition, Springer, 2009</p>
</li>
<li><p><a href="https://www.ams.org/books/pcms/025/" target=&ldquo;blank&rdquo;>The Mathematics of Data</a> (MD),  Editors: Michael W. Mahoney, John C. Duchi, and Anna C. Gilbert, AMS, IAS, SIAM, 2018</p>
</li>
<li><p><a href="http://people.maths.ox.ac.uk/trefethen/text.html" target=&ldquo;blank&rdquo;>Numerical Linear Algebra</a> (NLA), <a href="http://people.maths.ox.ac.uk/trefethen/" target=&ldquo;blank&rdquo;>Lloyd N. Trefethen</a> and David Bau, III, SIAM, 1997</p>
</li>
<li><p><a href="https://bicmr.pku.edu.cn/~wenzw/optbook.html" target=&ldquo;blank&rdquo;>最优化：建模、算法与理论/最优化计算方法</a>，刘浩洋，户将，李勇锋，<a href="https://bicmr.pku.edu.cn/~wenzw/index.html" target=&ldquo;blank&rdquo;>文再文</a>，高等教育出版社，2020/2021</p>
</li>
<li><p><a href="https://archive.siam.org/books/mo19/" target=&ldquo;blank&rdquo;>Introduction to Nonlinear Optimization: Theory, Algorithms, and Applications with MATLAB</a> (INO), Amir Beck, SIAM, 2014</p>
</li>
<li><p><a href="http://archive.siam.org/books/mo25/" target=&ldquo;blank&rdquo;>First-Order Methods in Optimization</a> (FOMO), Amir Beck, SIAM, 2017
</p>
</li>
<li><p><a href="https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.html" target=&ldquo;blank&rdquo;>High-Dimensional Probability: An Introduction with Applications in Data Science</a> (HDP), <a href="https://www.math.uci.edu/~rvershyn/" target=&ldquo;blank&rdquo;>Roman Vershynin</a>, Cambridge, 2017</p>
</li>
</ul>
<h2>Lecture Notes (tentative)</h2>
<ul>
<li><p><a href="http://kuidu.github.io/damc01.pdf" target=&ldquo;blank&rdquo;>Lecture 1: Preliminaries I. Probability</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc02.pdf" target=&ldquo;blank&rdquo;>Lecture 2: Preliminaries II. Linear Algebra</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc03.pdf" target=&ldquo;blank&rdquo;>Lecture 3: Randomized Iterative Methods for Linear Systems</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc04.pdf" target=&ldquo;blank&rdquo;>Lecture 4: Principal Component Analysis</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc05.pdf" target=&ldquo;blank&rdquo;>Lecture 5: Linear Discriminant Analysis</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc06.pdf" target=&ldquo;blank&rdquo;>Lecture 6: Nonnegative Matrix Factorization</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc07.pdf" target=&ldquo;blank&rdquo;>Lecture 7: Preliminaries III. Optimization</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc08.pdf" target=&ldquo;blank&rdquo;>Lecture 8: Preliminaries IV. Convex Analysis</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc09.pdf" target=&ldquo;blank&rdquo;>Lecture 9: Support Vector Machine</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc10.pdf" target=&ldquo;blank&rdquo;>Lecture 10: Page Ranking</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc11.pdf" target=&ldquo;blank&rdquo;>Lecture 11: Concentration of Sums of Independent Random Variables</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc12.pdf" target=&ldquo;blank&rdquo;>Lecture 12: Concentration of Sums of Independent Random Matrices</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc13.pdf" target=&ldquo;blank&rdquo;>Lecture 13: Covariance Estimation and Matrix Completion</a>.</p>
</li>
<li><p><a href="http://kuidu.github.io/damc14.pdf" target=&ldquo;blank&rdquo;>Lecture 14: Matrix Deviation Inequality</a>.














</p>
</li>
</ul>
<h2>Assignments (tentative)</h2>
<ul>
<li><p>Policy: No extension will be granted. Late submission will not be accepted. No exceptions!<br /> </p>
</li>
<li><p><a href="http://kuidu.github.io/damc_a1.pdf" target=&ldquo;blank&rdquo;>Assignment 1.</a> <b>交作业日期：2022年4月12日。</b></p>
</li>
<li><p><a href="http://kuidu.github.io/damc_a2.pdf" target=&ldquo;blank&rdquo;>Assignment 2.</a> <b>交作业日期：2022年5月12日。</b> </p>
</li>
<li><p><a href="http://kuidu.github.io/damc_a3.pdf" target=&ldquo;blank&rdquo;>Assignment 3.</a> <b>交作业日期：2022年5月31日。</b>




</p>
</li>
</ul>
<h2>Projects (tentative)</h2>
<ul>
<li><p>项目1：随机迭代法。阅读下面论文，完成相应数值实验，撰写实验报告。<br /> <a href="https://doi.org/10.1137/18M1179213" target=&ldquo;blank&rdquo;>Randomized Projection Methods for Linear Systems with Arbitrarily Large Sparse Corruptions</a>, SISC, 2019. <br /> <b>交报告日期：2022年4月19日。</b></p>
</li>
<li><p>项目2：非负矩阵分解。阅读下面论文，完成相应数值实验，撰写实验报告。<br /> <a href="https://doi.org/10.1016/j.patrec.2018.01.007" target=&ldquo;blank&rdquo;>Randomized nonnegative matrix factorization</a>, Pattern Recognition Letters, 2018. <br /> <b>交报告日期：2022年5月12日。</b>
</p>
</li>
<li><p>项目3：支持向量机。对给定的二维数据集测试支持向量机算法，要求标出支持向量，画出分隔线，并讨论不同参数对结果的影响。<br /> <b>交报告日期：2022年5月31日。</b>




</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
